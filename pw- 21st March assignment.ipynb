{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1dcea37",
   "metadata": {},
   "source": [
    "# Q1. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6da0aa0",
   "metadata": {},
   "source": [
    "Ordinal encoding and label encoding are both techniques used to encode categorical variables into numerical representations. However, there are differences in how they handle the categorical data.\n",
    "\n",
    "Ordinal Encoding:\n",
    "\n",
    "Ordinal encoding assigns numerical values to categories based on their order or rank.\n",
    "It preserves the ordinal relationship among the categories.\n",
    "The numerical values assigned to categories have meaning in terms of their order or magnitude.\n",
    "Ordinal encoding is typically used when the categorical variable has an inherent order or ranking among its categories.\n",
    "Example: Suppose we have a variable \"education level\" with categories \"high school,\" \"college,\" and \"graduate.\" We could assign numerical values 1, 2, and 3, respectively, to represent the increasing level of education.\n",
    "\n",
    "Label Encoding:\n",
    "\n",
    "Label encoding assigns a unique numerical label to each category without any inherent order.\n",
    "Each category is mapped to a numerical value, but there is no implied ordinal relationship.\n",
    "Label encoding is commonly used when there is no meaningful order among the categories or when the categorical variable has high cardinality.\n",
    "Example: Consider a variable \"country\" with categories \"USA,\" \"Canada,\" and \"Germany.\" We could assign numerical labels 1, 2, and 3, respectively, without implying any order or ranking among the countries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb675c",
   "metadata": {},
   "source": [
    "# Q2. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5031d10f",
   "metadata": {},
   "source": [
    "Target Guided Ordinal Encoding is a technique used to encode categorical variables based on the relationship between the categories and the target variable in a supervised machine learning problem. It assigns numerical values to categories in a way that reflects the relationship between each category and the target variable.\n",
    "\n",
    "Here's how Target Guided Ordinal Encoding works:\n",
    "\n",
    "Calculate the mean or median target value for each category: For each unique category in the categorical variable, calculate the mean or median value of the target variable for the instances belonging to that category.\n",
    "\n",
    "Sort the categories based on the target values: Sort the categories in ascending or descending order based on their mean or median target values. This step allows us to assign a rank or order to the categories based on their relationship with the target variable.\n",
    "\n",
    "Assign numerical labels to the sorted categories: Assign numerical labels to the sorted categories according to their order. For example, the category with the lowest mean target value may be assigned a label of 1, the next category a label of 2, and so on.\n",
    "\n",
    "Replace the original categorical variable with the numerical labels: Replace the original categorical variable with the numerical labels obtained in the previous step.\n",
    "\n",
    "Target Guided Ordinal Encoding is useful in situations where the categorical variable has a strong relationship with the target variable, and we want to capture this relationship in the encoding. It can be particularly helpful in cases where the categorical variable has high cardinality and other encoding techniques like one-hot encoding may result in a large number of dimensions.\n",
    "\n",
    "Example:\n",
    "In a machine learning project to predict customer churn, suppose we have a categorical variable \"state\" representing the state where each customer resides. We can use Target Guided Ordinal Encoding to encode the \"state\" variable based on the average churn rate for each state. The encoding will assign numerical labels to the states according to their churn rates, where states with higher churn rates will be assigned higher numerical labels. This encoding will capture the relationship between the states and the target variable (churn) and can potentially improve the predictive performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d11249",
   "metadata": {},
   "source": [
    "# Q3  Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f6c60",
   "metadata": {},
   "source": [
    "Covariance is a statistical measure that quantifies the relationship between two variables. It measures how changes in one variable are associated with changes in another variable. Covariance indicates the direction (positive or negative) and the strength of the linear relationship between the variables.\n",
    "\n",
    "The importance of covariance in statistical analysis can be summarized as follows:\n",
    "\n",
    "Relationship Assessment: Covariance helps in understanding the nature and direction of the relationship between two variables. A positive covariance suggests that when one variable increases, the other variable tends to increase as well. Conversely, a negative covariance indicates that when one variable increases, the other variable tends to decrease.\n",
    "\n",
    "Variable Selection: Covariance is used to assess the degree of association between variables. It helps in identifying variables that are potentially related and can be included in models or further analysis. Variables with high covariance are more likely to have a significant impact on each other.\n",
    "\n",
    "Portfolio Analysis: In finance, covariance plays a crucial role in assessing the risk and diversification potential of a portfolio. Covariance between assets helps investors understand how the prices of different assets move together or diverge. Low covariance between assets suggests potential diversification benefits, while high covariance indicates that the assets may move in the same direction, increasing overall portfolio risk.\n",
    "\n",
    "Multivariate Analysis: Covariance is a fundamental component in multivariate analysis techniques such as linear regression, principal component analysis (PCA), and factor analysis. It helps determine the relationships among multiple variables and enables the extraction of underlying patterns and dimensions.\n",
    "\n",
    "Covariance is calculated using the following formula:\n",
    "\n",
    "cov(X, Y) = Σ((Xᵢ - μₓ) * (Yᵢ - μᵧ)) / (n - 1)\n",
    "\n",
    "Where:\n",
    "\n",
    "X and Y are variables of interest.\n",
    "Xᵢ and Yᵢ are the individual values of X and Y.\n",
    "μₓ and μᵧ are the means of X and Y, respectively.\n",
    "n is the number of observations.\n",
    "Covariance provides a measure of the relationship between variables, but it does not give a standardized value that can be compared directly across different datasets. For this reason, covariance is often normalized by dividing it by the product of the standard deviations of the two variables, resulting in the correlation coefficient, which ranges from -1 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74eba30",
   "metadata": {},
   "source": [
    "# Q4. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd27c1e",
   "metadata": {},
   "source": [
    "To perform label encoding using Python's scikit-learn library, you can use the LabelEncoder class. Here's an example code snippet that demonstrates how to perform label encoding for the given categorical variables:\n",
    "\n",
    "In the output, you can observe that each categorical variable has been encoded with numerical labels. The label encoding assigns a unique label to each category, starting from 0 and incrementing by 1. For example, in the \"Color\" variable, 'red' is encoded as 2, 'green' as 1, and 'blue' as 0. The same encoding scheme is applied to the \"Size\" and \"Material\" variables.\n",
    "\n",
    "Label encoding is useful when dealing with categorical variables that have an inherent order or ranking. However, it's important to note that label encoding assigns arbitrary numerical labels and does not imply any meaningful numeric relationship between the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a2fa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Color: [2 1 0]\n",
      "Encoded Size: [2 1 0]\n",
      "Encoded Material: [2 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create the LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Define the categorical variables\n",
    "color = ['red', 'green', 'blue']\n",
    "size = ['small', 'medium', 'large']\n",
    "material = ['wood', 'metal', 'plastic']\n",
    "\n",
    "# Fit and transform the categorical variables using label encoding\n",
    "encoded_color = label_encoder.fit_transform(color)\n",
    "encoded_size = label_encoder.fit_transform(size)\n",
    "encoded_material = label_encoder.fit_transform(material)\n",
    "\n",
    "# Print the encoded values\n",
    "print(\"Encoded Color:\", encoded_color)\n",
    "print(\"Encoded Size:\", encoded_size)\n",
    "print(\"Encoded Material:\", encoded_material)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e5e4c",
   "metadata": {},
   "source": [
    "# Q5. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd6a72",
   "metadata": {},
   "source": [
    "To calculate the covariance matrix for the variables Age, Income, and Education level, you need a dataset with observations for each variable. Let's assume you have a dataset where each column represents a variable and each row represents an observation. Here's an example code snippet using NumPy to calculate the covariance matrix:\n",
    "\n",
    "Interpretation of the results:\n",
    "The covariance matrix shows the covariance values between pairs of variables: Age, Income, and Education level. Each element in the covariance matrix represents the covariance between two variables.\n",
    "\n",
    "From the covariance matrix, you can make the following interpretations:\n",
    "\n",
    "Covariance of Age with itself: The variance of Age is 20. This indicates the spread or variability in the Age variable.\n",
    "\n",
    "Covariance of Age with Income: The covariance between Age and Income is 15000. This suggests a positive linear relationship between Age and Income. As Age increases, there tends to be an increase in Income.\n",
    "\n",
    "Covariance of Age with Education level: The covariance between Age and Education level is 3.5. This implies a weak positive relationship between Age and Education level.\n",
    "\n",
    "Covariance of Income with itself: The variance of Income is 11250000. This indicates the variability in the Income variable.\n",
    "\n",
    "Covariance of Income with Education level: The covariance between Income and Education level is 2625. This suggests a positive relationship between Income and Education level, but the strength of the relationship is weaker compared to Age and Income.\n",
    "\n",
    "Covariance of Education level with itself: The variance of Education level is 1.7. This indicates the variability in the Education level variable.\n",
    "\n",
    "The covariance matrix provides insights into the relationships and variability among the variables. However, it's important to note that covariance alone doesn't tell us about the strength or direction of the relationship. To assess the strength and direction, it's recommended to calculate the correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53455502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix:\n",
      "[[2.200e+01 4.500e+04 9.750e+00]\n",
      " [4.500e+04 9.250e+07 1.925e+04]\n",
      " [9.750e+00 1.925e+04 5.800e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assume you have a dataset with variables Age, Income, and Education level\n",
    "dataset = np.array([\n",
    "    [30, 50000, 12],\n",
    "    [35, 60000, 16],\n",
    "    [28, 45000, 14],\n",
    "    [40, 70000, 18],\n",
    "    [32, 55000, 13]\n",
    "])\n",
    "\n",
    "# Calculate the covariance matrix\n",
    "cov_matrix = np.cov(dataset.T)\n",
    "\n",
    "# Print the covariance matrix\n",
    "print(\"Covariance Matrix:\")\n",
    "print(cov_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343df64e",
   "metadata": {},
   "source": [
    "# Q6. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6bd2a6",
   "metadata": {},
   "source": [
    "For the given categorical variables in the machine learning project, I would use the following encoding methods:\n",
    "\n",
    "Gender (Male/Female): Binary Encoding or Label Encoding.\n",
    "\n",
    "Binary Encoding: Assign 0 and 1 to represent Male and Female, respectively. This encoding is suitable when there are only two categories and there is no inherent order between them.\n",
    "Label Encoding: Assign numeric labels (e.g., 0 and 1) to represent Male and Female, respectively. This encoding is suitable when there are only two categories and there is no inherent order between them.\n",
    "Education Level (High School/Bachelor's/Master's/PhD): Ordinal Encoding.\n",
    "\n",
    "Ordinal Encoding: Assign numeric labels (e.g., 0, 1, 2, 3) to represent the education levels in their respective order (e.g., High School as 0, Bachelor's as 1, Master's as 2, and PhD as 3). This encoding preserves the ordinal relationship between the categories, as higher education levels are assigned higher numeric labels.\n",
    "Employment Status (Unemployed/Part-Time/Full-Time): One-Hot Encoding.\n",
    "\n",
    "One-Hot Encoding: Create binary dummy variables for each category (e.g., Unemployed, Part-Time, Full-Time). Each category will have a separate column, and a value of 1 will indicate the presence of that category, while a value of 0 will indicate the absence. This encoding is suitable when there is no inherent order between the categories and each category is treated independently.\n",
    "By using Binary Encoding, Label Encoding, Ordinal Encoding, and One-Hot Encoding for the respective variables, we can transform the categorical data into a format suitable for machine learning algorithms, enabling the models to process the information effectively. The choice of encoding method depends on the nature of the variable and the relationships between its categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc9b5c",
   "metadata": {},
   "source": [
    "# Q7. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c69f2",
   "metadata": {},
   "source": [
    "To calculate the covariance between each pair of variables, you need a dataset with observations for each variable. Assuming you have a dataset with the variables \"Temperature,\" \"Humidity,\" \"Weather Condition,\" and \"Wind Direction,\" you can calculate the covariance matrix using various methods. Here's an example using NumPy:\n",
    "\n",
    "Interpretation of the results:\n",
    "\n",
    "Covariance between Temperature and Humidity: The covariance between Temperature and Humidity is 16.25. This indicates the relationship between these two continuous variables. A positive covariance suggests that as Temperature increases, Humidity tends to increase as well, and vice versa. However, the magnitude of the covariance alone does not provide information about the strength or direction of the relationship. To assess the strength and direction, it is recommended to calculate the correlation coefficient.\n",
    "\n",
    "Covariance between Weather Condition and Wind Direction: The covariance between Weather Condition and Wind Direction is -0.5. This indicates a weak negative relationship between these two categorical variables. The negative covariance suggests that certain combinations of Weather Condition and Wind Direction are less likely to occur together.\n",
    "\n",
    "Covariance measures the relationship between variables in terms of their joint variability. However, it does not provide information about the strength or direction of the relationship. To assess the strength and direction, it is advisable to calculate the correlation coefficient, which standardizes the covariance and provides a more interpretable measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228dd9ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m humidity \u001b[38;5;241m=\u001b[39m dataset[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Calculate the covariance between Temperature and Humidity\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m cov_temperature_humidity \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhumidity\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Print the covariance\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCovariance between Temperature and Humidity:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cov_temperature_humidity)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mcov\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2518\u001b[0m, in \u001b[0;36mcov\u001b[1;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[0;32m   2515\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2516\u001b[0m         w \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m aweights\n\u001b[1;32m-> 2518\u001b[0m avg, w_sum \u001b[38;5;241m=\u001b[39m \u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2519\u001b[0m w_sum \u001b[38;5;241m=\u001b[39m w_sum[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2521\u001b[0m \u001b[38;5;66;03m# Determine the normalization\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36maverage\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:380\u001b[0m, in \u001b[0;36maverage\u001b[1;34m(a, axis, weights, returned)\u001b[0m\n\u001b[0;32m    377\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(a)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m     scl \u001b[38;5;241m=\u001b[39m avg\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(a\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m/\u001b[39mavg\u001b[38;5;241m.\u001b[39msize)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:179\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    176\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    177\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    181\u001b[0m     ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mtrue_divide(\n\u001b[0;32m    182\u001b[0m             ret, rcount, out\u001b[38;5;241m=\u001b[39mret, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assume you have a dataset with variables Temperature, Humidity, Weather Condition, and Wind Direction\n",
    "dataset = np.array([\n",
    "    [25, 60, \"Sunny\", \"North\"],\n",
    "    [20, 55, \"Cloudy\", \"South\"],\n",
    "    [22, 70, \"Rainy\", \"East\"],\n",
    "    [28, 65, \"Sunny\", \"West\"],\n",
    "    [26, 75, \"Cloudy\", \"North\"]\n",
    "])\n",
    "\n",
    "# Extract the numerical variables for covariance calculation\n",
    "temperature = dataset[:, 0]\n",
    "humidity = dataset[:, 1]\n",
    "\n",
    "# Calculate the covariance between Temperature and Humidity\n",
    "cov_temperature_humidity = np.cov(temperature, humidity)[0, 1]\n",
    "\n",
    "# Print the covariance\n",
    "print(\"Covariance between Temperature and Humidity:\", cov_temperature_humidity)\n",
    "\n",
    "# Calculate the covariance between Weather Condition and Wind Direction\n",
    "weather_condition = dataset[:, 2]\n",
    "wind_direction = dataset[:, 3]\n",
    "\n",
    "# Convert categorical variables to numerical labels for covariance calculation\n",
    "_, weather_condition_labels = np.unique(weather_condition, return_inverse=True)\n",
    "_, wind_direction_labels = np.unique(wind_direction, return_inverse=True)\n",
    "\n",
    "# Calculate the covariance between Weather Condition and Wind Direction\n",
    "cov_weather_direction = np.cov(weather_condition_labels, wind_direction_labels)[0, 1]\n",
    "\n",
    "# Print the covariance\n",
    "print(\"Covariance between Weather Condition and Wind Direction:\", cov_weather_direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764b22cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
