{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5be61e8",
   "metadata": {},
   "source": [
    "# Q1. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25855dc5",
   "metadata": {},
   "source": [
    "A method for automatic feature selection in anomaly detection is proposed which determines optimal mixture coefficients for various sets of features. The method generalizes the support vector data description (SVDD) and can be expressed as a semi-infinite linear program that can be solved with standard techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca02a98",
   "metadata": {},
   "source": [
    "# Q2. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045cfcb4",
   "metadata": {},
   "source": [
    "There are several common evaluation metrics for anomaly detection algorithms. Here are a few examples:\n",
    "\n",
    "True Positive Rate (TPR) or Recall: It measures the proportion of actual anomalies that are correctly identified by the algorithm. It is calculated as TP / (TP + FN), where TP is the number of true positives (correctly detected anomalies) and FN is the number of false negatives (missed anomalies).\n",
    "\n",
    "False Positive Rate (FPR): It measures the proportion of non-anomalies that are incorrectly classified as anomalies. It is calculated as FP / (FP + TN), where FP is the number of false positives (non-anomalies classified as anomalies) and TN is the number of true negatives (correctly classified non-anomalies).\n",
    "\n",
    "Precision: It measures the proportion of correctly identified anomalies out of all instances classified as anomalies. It is calculated as TP / (TP + FP).\n",
    "\n",
    "F1-Score: It is the harmonic mean of precision and recall, providing a balanced measure of the model's performance. It is calculated as 2 * (Precision * Recall) / (Precision + Recall).\n",
    "\n",
    "Area Under the Receiver Operating Characteristic curve (AUROC): It is a popular metric that plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various classification thresholds. The AUROC value ranges from 0 to 1, with higher values indicating better performance.\n",
    "\n",
    "Average Precision (AP): It calculates the average precision across all recall levels and is particularly useful when dealing with imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01a5d6d",
   "metadata": {},
   "source": [
    "# Q3. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a59d75",
   "metadata": {},
   "source": [
    "DBSCAN is a density-based clustering algorithm that works on the assumption that clusters are dense regions in space separated by regions of lower density. It groups 'densely grouped' data points into a single cluster.\n",
    "\n",
    "The Density-based Clustering tool works by detecting areas where points are concentrated and where they are separated by areas that are empty or sparse. Points that are not part of a cluster are labeled as noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9651257b",
   "metadata": {},
   "source": [
    "# Q4. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c353e0b1",
   "metadata": {},
   "source": [
    "The epsilon (ε) parameter in DBSCAN determines the maximum distance between two points for them to be considered neighbors. It directly affects the performance of DBSCAN in detecting anomalies by influencing the size and shape of the detected clusters.\n",
    "\n",
    "The impact of the epsilon parameter on anomaly detection can be summarized as follows:\n",
    "\n",
    "Smaller Epsilon: Choosing a smaller epsilon value will result in tighter clusters. It means that points need to be closer to each other to be considered neighbors. As a result, anomalies that are far away from other data points or lie in sparse regions may not be included in any cluster and are more likely to be identified as outliers or anomalies.\n",
    "\n",
    "Larger Epsilon: Increasing the epsilon value will lead to larger clusters as more points will be considered neighbors. This can result in anomalies being included within larger clusters, reducing their distinctiveness and making it more challenging to identify them as outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9de94c",
   "metadata": {},
   "source": [
    "# Q5. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7dc31b",
   "metadata": {},
   "source": [
    "In DBSCAN (Density-Based Spatial Clustering of Applications with Noise), data points are classified into three categories: core points, border points, and noise points. These categories play a role in anomaly detection as they provide insights into the density and structure of the data.\n",
    "\n",
    "Core Points: Core points are data points that have at least the minimum number of neighboring points (specified by the min_samples parameter) within a distance of epsilon (ε). These points are at the heart of clusters and contribute to the cluster's density. Core points are often considered as normal or non-anomalous points since they are surrounded by a sufficient number of similar points.\n",
    "\n",
    "Border Points: Border points are data points that have fewer neighboring points than the minimum required but are within the distance of epsilon (ε) from a core point. These points lie on the edge of clusters and are less dense than core points. Border points can be considered as ambiguous or less certain points in terms of their anomaly status. They can belong to a cluster but have a lower level of confidence compared to core points.\n",
    "\n",
    "Noise Points: Noise points, also known as outliers, are data points that do not meet the criteria for core or border points. They do not have enough neighboring points within the specified epsilon distance. Noise points are typically considered as anomalies since they do not conform to the density-based clustering patterns of the majority of the data.\n",
    "\n",
    "The distinction between these categories is useful for anomaly detection because anomalies are often characterized by their deviation from the normal density patterns. Noise points, which do not belong to any cluster, can be seen as potential anomalies, while core and border points are more likely to represent normal data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4e1872",
   "metadata": {},
   "source": [
    "# Q6. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2413a3fb",
   "metadata": {},
   "source": [
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is primarily designed for clustering, but it can also be used for anomaly detection. DBSCAN detects anomalies by considering data points that do not belong to any cluster as noise points or outliers. Here's how DBSCAN detects anomalies and the key parameters involved in the process:\n",
    "\n",
    "Density-Based Clustering: DBSCAN defines clusters based on the density of data points. It identifies dense regions in the data space as clusters and considers areas with low data density as anomalies.\n",
    "\n",
    "Key Parameters:\n",
    "\n",
    "Epsilon (ε): Also known as the radius, epsilon defines the maximum distance that two points can be from each other to be considered as neighbors. It determines the neighborhood of a point.\n",
    "Min_samples: Min_samples specifies the minimum number of points that must be within the epsilon distance for a point to be classified as a core point. Points with fewer neighbors are considered outliers.\n",
    "Core Points: Core points are data points that have at least the minimum number of neighboring points (min_samples) within the epsilon distance. They are considered as part of a cluster and are not anomalies.\n",
    "\n",
    "Density-Reachable: DBSCAN identifies density-reachable points, which are points within the epsilon distance of a core point, even if they do not have enough neighbors themselves. Density-reachable points are part of the same cluster as the core point.\n",
    "\n",
    "Border Points: Border points are data points that have fewer neighbors than the minimum required to be core points but are within the epsilon distance of a core point. They are part of a cluster but have a lower level of density than core points.\n",
    "\n",
    "Noise Points: Noise points, also known as outliers, are data points that do not belong to any cluster. They are not classified as core points or border points because they do not meet the requirements for either."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088200b0",
   "metadata": {},
   "source": [
    "# Q7. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4aaf8f",
   "metadata": {},
   "source": [
    "The make_circles function in scikit-learn is used to generate a synthetic dataset consisting of concentric circles. It is primarily used for testing and illustrating the performance of machine learning algorithms, particularly those that are designed to handle non-linearly separable data.\n",
    "\n",
    "The make_circles function allows you to create a dataset with two classes, where each class forms a separate circle in the feature space. You can control various parameters of the dataset, such as the number of samples, noise level, and the ratio of inter-class and intra-class distances.\n",
    "\n",
    "This synthetic dataset is useful for evaluating algorithms that are capable of capturing complex, non-linear relationships. For example, it can be used to test the performance of clustering algorithms like DBSCAN or density-based methods, as well as non-linear classifiers like support vector machines (SVM) or neural networks.\n",
    "\n",
    "By using the make_circles function, you can generate a controlled dataset that exhibits specific characteristics, allowing you to study and analyze the behavior of different machine learning algorithms in the presence of non-linearly separable data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c49fdcc",
   "metadata": {},
   "source": [
    "# Q8. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95139bc",
   "metadata": {},
   "source": [
    "There are two general types of outlier detection: global and local. Global outliers fall outside the normal range for an entire dataset, whereas local outliers may fall within the normal range for the entire dataset, but outside the normal range for the surrounding data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52230a8",
   "metadata": {},
   "source": [
    "# Q9. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83f3ae6",
   "metadata": {},
   "source": [
    "The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d6aac",
   "metadata": {},
   "source": [
    "# Q10. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d78cbe",
   "metadata": {},
   "source": [
    "The Isolation Forest algorithm can be used to detect global outliers in a dataset. In the Isolation Forest algorithm, anomalies are identified based on their tendency to have shorter average path lengths in the isolation trees.\n",
    "\n",
    "To detect global outliers using the Isolation Forest algorithm, you can follow these steps:\n",
    "\n",
    "Train the Isolation Forest model on the dataset that contains both normal and potentially anomalous data points.\n",
    "\n",
    "For each data point in the dataset, compute its anomaly score. The anomaly score represents the average path length required to isolate the data point in the isolation trees.\n",
    "\n",
    "Sort the data points based on their anomaly scores in ascending order. Data points with lower anomaly scores are considered less likely to be outliers, while data points with higher anomaly scores are considered more likely to be outliers.\n",
    "\n",
    "Set a threshold for determining which data points are considered outliers. The threshold can be determined based on domain knowledge or by analyzing the distribution of anomaly scores.\n",
    "\n",
    "Identify the data points with anomaly scores above the threshold as global outliers. These data points are considered to be significantly different from the majority of the data points in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e67d951",
   "metadata": {},
   "source": [
    "# Q11. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ea185",
   "metadata": {},
   "source": [
    "Local outlier detection and global outlier detection have their own specific use cases depending on the nature of the data and the context of the problem. Here are some examples of real-world applications where one approach may be more appropriate than the other:\n",
    "\n",
    "Local Outlier Detection:\n",
    "\n",
    "Fraud Detection: In financial transactions, detecting local anomalies within a specific user's transaction history can help identify fraudulent activities that deviate from their normal behavior.\n",
    "Network Intrusion Detection: Local outlier detection can be used to identify abnormal behavior or anomalies within a specific network segment or user's network traffic.\n",
    "Disease Outbreak Detection: Local outlier detection can be applied to detect local clusters of disease outbreaks within a specific geographic region, helping to identify potential epidemics or outbreaks.\n",
    "Global Outlier Detection:\n",
    "\n",
    "Manufacturing Quality Control: Global outlier detection can be useful for identifying faulty products or components that deviate significantly from the norm across the entire manufacturing process.\n",
    "Anomaly Detection in Sensor Networks: Global outlier detection can help identify sensor readings that deviate from the expected patterns across a network of sensors, indicating potential equipment malfunctions or abnormal conditions.\n",
    "Credit Card Fraud Detection: Global outlier detection can be applied to identify unusual patterns or anomalies in credit card transactions across a large customer base, helping to detect fraudulent activities that span multiple accounts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
