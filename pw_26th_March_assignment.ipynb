{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "822f78f7-4a1e-4b02-ac5f-63cda1578843",
      "metadata": {
        "id": "822f78f7-4a1e-4b02-ac5f-63cda1578843"
      },
      "source": [
        "Q1. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51318eae-847e-497e-bc4c-bf5df655b506",
      "metadata": {
        "id": "51318eae-847e-497e-bc4c-bf5df655b506"
      },
      "source": [
        "Simple linear regression is a regression model that estimates the relationship between one independent variable and one dependent variable using a straight line. Both variables should be quantitative. Ex: finding a relationship between the revenue and temperature, with a sample size for revenue as the dependent variable.\n",
        "\n",
        "Multiple Linear Regression is one of the important regression algorithms which models the linear relationship between a single dependent continuous variable and more than one independent variable. Example: Prediction of CO2 emission based on engine size and number of cylinders in a car."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c548eea-d6b6-461d-9a1b-259c73512078",
      "metadata": {
        "id": "0c548eea-d6b6-461d-9a1b-259c73512078"
      },
      "source": [
        "Q2. Ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edf6830d-8b6f-4a56-9964-53a6f4668180",
      "metadata": {
        "id": "edf6830d-8b6f-4a56-9964-53a6f4668180"
      },
      "outputs": [],
      "source": [
        "There are primarily five assumptions of linear regression. They are:\n",
        "\n",
        "1. There is a linear relationship between the predictors (x) and the outcome (y)\n",
        "2. Predictors (x) are independent and observed with negligible error\n",
        "3. Residual Errors have a mean value of zero\n",
        "4. Residual Errors have constant variance\n",
        "5. Residual Errors are independent from each other and predictors (x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a7b88bf-2f63-48cf-8b9c-95b9f4ae13ed",
      "metadata": {
        "id": "2a7b88bf-2f63-48cf-8b9c-95b9f4ae13ed"
      },
      "source": [
        "Q3. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ad214fe-f371-4682-ad47-ce1d059c60f3",
      "metadata": {
        "id": "4ad214fe-f371-4682-ad47-ce1d059c60f3"
      },
      "source": [
        "The slope indicates the steepness of a line and the intercept indicates the location where it intersects an axis. The slope and the intercept define the linear relationship between two variables, and can be used to estimate an average rate of change.\n",
        "\n",
        "For example, it can be used to predict the relationship between reckless driving and the total number of road accidents caused by a driver, or, to use a business example, the effect on sales and spending a certain amount of money on advertising. Regression is one of the most common models of machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e087bc7-45f0-4a49-92d4-d5dc71b3c668",
      "metadata": {
        "id": "6e087bc7-45f0-4a49-92d4-d5dc71b3c668"
      },
      "source": [
        "Q4. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe7bb62-0a7f-495f-a573-108fc19fd462",
      "metadata": {
        "id": "afe7bb62-0a7f-495f-a573-108fc19fd462"
      },
      "source": [
        "Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks. Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates.\n",
        "\n",
        "Linear Regression, Logistic Regression, Neural Networks â€¦ all these models can use Gradient Descent algorithm to learn, let's understand the idea behind."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "408e5bfe-fc3f-4f34-808a-46cba6442b5c",
      "metadata": {
        "id": "408e5bfe-fc3f-4f34-808a-46cba6442b5c"
      },
      "source": [
        "Q5. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abfa7710-49e8-40b0-86aa-850d7da19b19",
      "metadata": {
        "id": "abfa7710-49e8-40b0-86aa-850d7da19b19"
      },
      "source": [
        "Multiple linear regression is a regression model that estimates the relationship between a quantitative dependent variable and two or more independent variables using a straight line.\n",
        "\n",
        "Multiple regression is a broader class of regressions that encompasses linear and nonlinear regressions with multiple explanatory variables. Whereas linear regress only has one independent variable impacting the slope of the relationship, multiple regression incorporates multiple independent variables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a1c0320-a7f9-487b-b2bb-ce6fa787a047",
      "metadata": {
        "id": "9a1c0320-a7f9-487b-b2bb-ce6fa787a047"
      },
      "source": [
        "Q6. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de754fa9-641c-4654-85fd-8d6c425b75e6",
      "metadata": {
        "id": "de754fa9-641c-4654-85fd-8d6c425b75e6"
      },
      "source": [
        "Multicollinearity occurs when two or more independent variables in a data frame have a high correlation with one another in a regression model. This means that one independent variable can be predicted from another in a regression model.\n",
        "\n",
        "Adressing it\n",
        "1. Removing variables. A straightforward method of correcting multicollinearity is removing one or more variables showing a high correlation.\n",
        "2. More data. Statistically, a regression model with more data is likely to suffer less variance due to a larger sample size. This will reduce the impact of multicollinearity.\n",
        "3. Using techniques such as partial least squares regression (PLS) and principal component analysis (PCA). A takeaway from this paper on partial least squares regression for multicollinearity is that PLS can lessen variables to a smaller grouping with no correlation between them.\n",
        "4. Centering the variables. Centering is defined as subtracting a constant from the value of every variable. It redefines the zero point for a given predictor to become the value we subtracted."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93fd72e0-1804-457f-b804-ce27d3b67c75",
      "metadata": {
        "id": "93fd72e0-1804-457f-b804-ce27d3b67c75"
      },
      "source": [
        "Q7. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58615f58-132a-454f-8abc-58e58eca0e06",
      "metadata": {
        "id": "58615f58-132a-454f-8abc-58e58eca0e06"
      },
      "source": [
        "Polynomial regression is a form of Linear regression where only due to the Non-linear relationship between dependent and independent variables, we add some polynomial terms to linear regression to convert it into Polynomial regression."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "208535af-8931-4c45-9b66-f34a2c0abbda",
      "metadata": {
        "id": "208535af-8931-4c45-9b66-f34a2c0abbda"
      },
      "source": [
        "Q8. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a39dd3b6-3591-4ecf-8893-a3826bb2aa4a",
      "metadata": {
        "id": "a39dd3b6-3591-4ecf-8893-a3826bb2aa4a"
      },
      "source": [
        "Advantages\n",
        "Polynomial provides the best approximation of the relationship between the dependent and independent variable. A Broad range of function can be fit under it. Polynomial basically fits a wide range of curvature.\n",
        "\n",
        "Disadvantages\n",
        "One or two outliers in the data might have a significant impact on the nonlinear analysis' outcomes. These are overly reliant on outliers. Furthermore, there are fewer model validation methods for detecting outliers in nonlinear regression than there are for linear regression.\n",
        "\n",
        "Uses\n",
        "A polynomial regression model is a machine learning model that can capture non-linear relationships between variables by fitting a non-linear regression line, which may not be possible with simple linear regression. It is used when linear regression models may not adequately capture the complexity of the relationship."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}