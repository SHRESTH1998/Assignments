{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aef1e849",
   "metadata": {},
   "source": [
    "# Q1. Ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf9b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Certainly! Here are five commonly used functions in the pandas library along with their execution:\n",
    "\n",
    "# read_csv(): This function is used to read data from a CSV file and create a DataFrame.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read data from a CSV file and create a DataFrame\n",
    "df = pd.read_csv('data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2af868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name           email_id  phone_number\n",
      "0    kumar    kumar@gmail.com       9876543\n",
      "1  shresth  shresth@gmail.com   98765437654\n"
     ]
    }
   ],
   "source": [
    "# head(): This function returns the first n rows of a DataFrame.\n",
    "\n",
    "# Print the first 5 rows of the DataFrame\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb298ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   name          2 non-null      object\n",
      " 1   email_id      2 non-null      object\n",
      " 2   phone_number  2 non-null      int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 176.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# info(): This function provides information about the DataFrame, including data types, non-null values, and memory usage.\n",
    "\n",
    "# Display information about the DataFrame\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32d0477c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       phone_number\n",
      "count  2.000000e+00\n",
      "mean   4.938766e+10\n",
      "std    6.983073e+10\n",
      "min    9.876543e+06\n",
      "25%    2.469877e+10\n",
      "50%    4.938766e+10\n",
      "75%    7.407655e+10\n",
      "max    9.876544e+10\n"
     ]
    }
   ],
   "source": [
    "# describe(): This function generates descriptive statistics of the DataFrame, such as count, mean, min, max, etc.\n",
    "\n",
    "# Generate descriptive statistics of the DataFrame\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666596ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Category'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# groupby(): This function is used for grouping and aggregating data based on one or more columns.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Group the DataFrame by 'Category' and calculate the average 'Price' for each group\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(grouped_data)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:7712\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7707\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   7709\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[0;32m   7710\u001b[0m \u001b[38;5;66;03m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   7711\u001b[0m \u001b[38;5;66;03m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 7712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7715\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7718\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7720\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    880\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 882\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Category'"
     ]
    }
   ],
   "source": [
    "# groupby(): This function is used for grouping and aggregating data based on one or more columns.\n",
    "\n",
    "# Group the DataFrame by 'Category' and calculate the average 'Price' for each group\n",
    "grouped_data = df.groupby('Category')['Price'].mean()\n",
    "print(grouped_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d5d54",
   "metadata": {},
   "source": [
    "# Q2. Ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74001cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B    C\n",
      "1  10  50   90\n",
      "3  20  60  100\n",
      "5  30  70  110\n",
      "7  40  80  120\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def reindex_dataframe(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.index = df.index * 2 + 1\n",
    "    return df\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {'A': [10, 20, 30, 40], 'B': [50, 60, 70, 80], 'C': [90, 100, 110, 120]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to re-index the DataFrame\n",
    "reindexed_df = reindex_dataframe(df)\n",
    "\n",
    "# Print the re-indexed DataFrame\n",
    "print(reindexed_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df8300b",
   "metadata": {},
   "source": [
    "# Q3. Ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d364bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of the first three values is: 60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_sum(df):\n",
    "    values_column = df['Values']\n",
    "    sum_first_three = values_column.head(3).sum()\n",
    "    print(\"The sum of the first three values is:\", sum_first_three)\n",
    "\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {'Values': [10, 20, 30, 40, 50]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to calculate the sum\n",
    "calculate_sum(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83aa776",
   "metadata": {},
   "source": [
    "# Q4. Ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93f746c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Text  Word_Count\n",
      "0  Hello, how are you?           4\n",
      "1    I am doing great!           4\n",
      "2   Python is awesome.           3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_word_count_column(df):\n",
    "    df['Word_Count'] = df['Text'].apply(lambda x: len(x.split()))\n",
    "    return df\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {'Text': ['Hello, how are you?', 'I am doing great!', 'Python is awesome.']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to add the 'Word_Count' column\n",
    "df = add_word_count_column(df)\n",
    "\n",
    "# Print the DataFrame with the 'Word_Count' column\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa16afba",
   "metadata": {},
   "source": [
    "# Q5. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0518f29a",
   "metadata": {},
   "source": [
    "The DataFrame.size and DataFrame.shape are different in terms of the information they provide:\n",
    "\n",
    "DataFrame.size: This attribute returns the total number of elements in the DataFrame, which is equivalent to the total number of cells in the DataFrame.\n",
    "\n",
    "DataFrame.shape: This attribute returns a tuple representing the dimensions of the DataFrame. It provides the number of rows and columns in the DataFrame.\n",
    "\n",
    "Here's an example to illustrate the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "413e8def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Size: 6\n",
      "DataFrame Shape: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate size and shape\n",
    "size = df.size\n",
    "shape = df.shape\n",
    "\n",
    "# Print the results\n",
    "print(\"DataFrame Size:\", size)\n",
    "print(\"DataFrame Shape:\", shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62f18fe",
   "metadata": {},
   "source": [
    "# Q6. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29141975",
   "metadata": {},
   "source": [
    "In Pandas, we use the pd.read_excel() function to read an Excel file. This function allows us to read data from Excel files and create a DataFrame.\n",
    "\n",
    "Here's an example of how to use pd.read_excel() to read an Excel file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ccd7f92",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Read an Excel file and create a DataFrame\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    456\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1376\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1376\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1381\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m         )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1250\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1248\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1253\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1254\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:798\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    794\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read an Excel file and create a DataFrame\n",
    "df = pd.read_excel('data.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f27fd2",
   "metadata": {},
   "source": [
    "# Q7. Ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7a09474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Email          Username\n",
      "0          john.doe@example.com          john.doe\n",
      "1        jane.smith@example.com        jane.smith\n",
      "2  alice.wonderland@example.com  alice.wonderland\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_username(df):\n",
    "    df['Username'] = df['Email'].str.split('@').str[0]\n",
    "    return df\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {'Email': ['john.doe@example.com', 'jane.smith@example.com', 'alice.wonderland@example.com']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to extract the username\n",
    "df = extract_username(df)\n",
    "\n",
    "# Print the DataFrame with the new 'Username' column\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e685a9",
   "metadata": {},
   "source": [
    "# Q8. Ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abd0a2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "1  8  2  7\n",
      "2  6  9  4\n",
      "4  9  1  2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def select_rows(df):\n",
    "    selected_rows = df[(df['A'] > 5) & (df['B'] < 10)]\n",
    "    return selected_rows\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {'A': [3, 8, 6, 2, 9], 'B': [5, 2, 9, 3, 1], 'C': [1, 7, 4, 5, 2]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to select rows\n",
    "selected_df = select_rows(df)\n",
    "\n",
    "# Print the selected DataFrame\n",
    "print(selected_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b5dea6",
   "metadata": {},
   "source": [
    "# Q9. Ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b28fc27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 30.0\n",
      "Median: 30.0\n",
      "Standard Deviation: 15.811388300841896\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_stats(df):\n",
    "    values_column = df['Values']\n",
    "    mean = values_column.mean()\n",
    "    median = values_column.median()\n",
    "    std_dev = values_column.std()\n",
    "    return mean, median, std_dev\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {'Values': [10, 20, 30, 40, 50]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to calculate statistics\n",
    "mean, median, std_dev = calculate_stats(df)\n",
    "\n",
    "# Print the statistics\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Standard Deviation:\", std_dev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5854a",
   "metadata": {},
   "source": [
    "# Q10. Ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccd32c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sales       Date  MovingAverage\n",
      "0     10 2023-01-01           10.0\n",
      "1     20 2023-01-02           15.0\n",
      "2     30 2023-01-03           20.0\n",
      "3     40 2023-01-04           25.0\n",
      "4     50 2023-01-05           30.0\n",
      "5     60 2023-01-06           35.0\n",
      "6     70 2023-01-07           40.0\n",
      "7     80 2023-01-08           50.0\n",
      "8     90 2023-01-09           60.0\n",
      "9    100 2023-01-10           70.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_moving_average(df):\n",
    "    df['MovingAverage'] = df['Sales'].rolling(window=7, min_periods=1).mean()\n",
    "    return df\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {'Sales': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 'Date': pd.date_range('2023-01-01', periods=10)}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to calculate the moving average\n",
    "df = calculate_moving_average(df)\n",
    "\n",
    "# Print the DataFrame with the 'MovingAverage' column\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c6aa7",
   "metadata": {},
   "source": [
    "# Q11. Ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75335de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date    Weekday\n",
      "0 2023-01-01     Sunday\n",
      "1 2023-01-02     Monday\n",
      "2 2023-01-03    Tuesday\n",
      "3 2023-01-04  Wednesday\n",
      "4 2023-01-05   Thursday\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_weekday_column(df):\n",
    "    df['Weekday'] = df['Date'].dt.strftime('%A')\n",
    "    return df\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {'Date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'])}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to add the 'Weekday' column\n",
    "df = add_weekday_column(df)\n",
    "\n",
    "# Print the DataFrame with the 'Weekday' column\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c8102",
   "metadata": {},
   "source": [
    "# Q12. Ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22b9fbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date\n",
      "0 2023-01-01\n",
      "1 2023-01-15\n",
      "2 2023-01-31\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def select_rows_between_dates(df):\n",
    "    start_date = pd.to_datetime('2023-01-01')\n",
    "    end_date = pd.to_datetime('2023-01-31')\n",
    "    selected_rows = df[df['Date'].between(start_date, end_date)]\n",
    "    return selected_rows\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {'Date': pd.to_datetime(['2023-01-01', '2023-01-15', '2023-01-31', '2023-02-05'])}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the function to select rows between dates\n",
    "selected_df = select_rows_between_dates(df)\n",
    "\n",
    "# Print the selected DataFrame\n",
    "print(selected_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7344369d",
   "metadata": {},
   "source": [
    "# Q13. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f952ffbd",
   "metadata": {},
   "source": [
    "To use the basic functions of pandas, the first and foremost necessary library that needs to be imported is the pandas library itself. The standard convention is to import it using the import statement with the alias pd. \n",
    "By importing pandas in this way, you can access all the pandas functions and classes using the pd alias. For example, you can use pd.DataFrame() to create a DataFrame or pd.Series() to create a Series.\n",
    "\n",
    "In addition to pandas, you may also need to import other libraries depending on your specific requirements. For example, if you want to work with numerical operations, you might need to import the NumPy library (import numpy as np). If you want to visualize data, you might need to import the Matplotlib library (import matplotlib.pyplot as plt).\n",
    "Here's an example:\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324857c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
