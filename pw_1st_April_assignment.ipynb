{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "312173cf",
   "metadata": {},
   "source": [
    "# Q1. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499cecf",
   "metadata": {},
   "source": [
    "Linear regression is used to predict the continuous dependent variable using a given set of independent variables. Linear Regression is used for solving Regression problem. In Linear regression, we predict the value of continuous variables.\n",
    "\n",
    "Logistic Regression is used to predict the categorical dependent variable using a given set of independent variables. Logistic regression is used for solving Classification problems. In logistic Regression, we predict the values of categorical variables.\n",
    "\n",
    "Eg:\n",
    "An example of logistic regression could be applying machine learning to determine if a person is likely to be infected with COVID-19 or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4a187c",
   "metadata": {},
   "source": [
    "# Q2. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f557f",
   "metadata": {},
   "source": [
    "The cost function used in Logistic Regression is Log Loss. This optimization takes place through algorithmic methods for learning. The method most commonly used for logistic regression is gradient descent. Gradient descent requires convex cost functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd1576a",
   "metadata": {},
   "source": [
    "# Q3. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e405a",
   "metadata": {},
   "source": [
    "Regularization is any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error. In other words regularization can be used to train models that generalize better on unseen data, by preventing the algorithm from overfitting the training dataset.\n",
    "\n",
    "Regularization helps you avoid overfitting by adding a penalty term to the cost function of your model, which measures how well your model fits the data. The penalty term reduces the complexity of your model by shrinking or eliminating some of the coefficients of your input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d9d60a",
   "metadata": {},
   "source": [
    "# Q4. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd9280",
   "metadata": {},
   "source": [
    "ROC curves in logistic regression are used for determining the best cutoff value for predicting whether a new observation is a \"failure\" (0) or a \"success\" (1). \n",
    "\n",
    "An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:\n",
    "\n",
    "True Positive Rate\n",
    "False Positive Rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028bdf7c",
   "metadata": {},
   "source": [
    "# Q5. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d288b92",
   "metadata": {},
   "source": [
    "There are several types of statistical tests that can be used for filter feature selection, including chi-square, ANOVA, and mutual information. These tests measure the degree of association between the features and the target variable, and can help identify the most relevant features for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bb11d8",
   "metadata": {},
   "source": [
    "# Q6. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8bb01b",
   "metadata": {},
   "source": [
    "In logistic regression, another technique comes handy to work with imbalance distribution. This is to use class-weights in accordance with the class distribution. Class-weights is the extent to which the algorithm is punished for any wrong prediction of that class.\n",
    "\n",
    "There are many techniques available to handle class imbalance. One of the popular techniques is up-sampling (e.g. SMOTE) in which more similar data points are added to minority class to make class distribution equal. On this up-sampled modified data, any classifier can be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ffaac",
   "metadata": {},
   "source": [
    "# Q7. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db5f3fd",
   "metadata": {},
   "source": [
    "Logistic regression fails to predict a continuous outcome.\n",
    "Logistic regression assumes linearity between the predicted (dependent) variable and the predictor (independent) variables.\n",
    "Logistic regression may not be accurate if the sample size is too small.\n",
    "\n",
    "This multicollinearity problem can be remedied by the following methods : â€¢ Respecification of the model that has been considered. Usage of additional data/collection of more data. Independent estimation of parameters. Placing of prior restrictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f188124c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
