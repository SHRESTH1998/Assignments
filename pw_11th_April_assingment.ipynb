{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eeadbab",
   "metadata": {},
   "source": [
    "# Q1. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a3a6a7",
   "metadata": {},
   "source": [
    "An ensemble method is a technique which uses multiple independent similar or different models/weak learners to derive an output or make some predictions. For e.g. A random forest is an ensemble of multiple decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3592657",
   "metadata": {},
   "source": [
    "# Q2. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c3969c",
   "metadata": {},
   "source": [
    "There are two main reasons to use an ensemble over a single model, and they are related; they are: Performance: An ensemble can make better predictions and achieve better performance than any single contributing model. Robustness: An ensemble reduces the spread or dispersion of the predictions and model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83998315",
   "metadata": {},
   "source": [
    "# Q3. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0d1c8",
   "metadata": {},
   "source": [
    "Bagging, also known as bootstrap aggregation, is the ensemble learning method that is commonly used to reduce variance within a noisy dataset. In bagging, a random sample of data in a training set is selected with replacement—meaning that the individual data points can be chosen more than once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b63b5",
   "metadata": {},
   "source": [
    "# Q4. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003d6736",
   "metadata": {},
   "source": [
    "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors. In boosting, a random sample of data is selected, fitted with a model and then trained sequentially—that is, each model tries to compensate for the weaknesses of its predecessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ef16ad",
   "metadata": {},
   "source": [
    "# Q.5.Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd5542a",
   "metadata": {},
   "source": [
    "Ensemble methods offer several advantages over single models, such as improved accuracy and performance, especially for complex and noisy problems. They can also reduce the risk of overfitting and underfitting by balancing the trade-off between bias and variance, and by using different subsets and features of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b16c010",
   "metadata": {},
   "source": [
    "# Q6. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7c61c8",
   "metadata": {},
   "source": [
    "Ensemble methods have higher predictive accuracy, compared to the individual models. 2. Ensemble methods are very useful when there is both linear and non-linear type of data in the dataset; different models can be combined to handle this type of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b3a390",
   "metadata": {},
   "source": [
    "# Q7. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62914775",
   "metadata": {},
   "source": [
    "The bootstrap method is a resampling technique used to estimate the sampling distribution of a statistic. It can be used to calculate confidence intervals by resampling the original data multiple times, generating bootstrap samples, and computing the statistic of interest for each sample. The following steps outline the general process of calculating a bootstrap confidence interval:\n",
    "\n",
    "Collect the original sample: Start with a dataset containing the original observations or data points.\n",
    "\n",
    "1. Resampling: Randomly select observations from the original sample with replacement to create a bootstrap sample. The size of the bootstrap sample is typically the same as the size of the original sample, but some observations may appear multiple times, while others may be left out.\n",
    "\n",
    "2. Calculate the statistic: Compute the desired statistic (mean, median, standard deviation, etc.) of interest using the bootstrap sample.\n",
    "\n",
    "3. Repeat steps 2 and 3: Repeat the resampling process multiple times (often a large number, such as 1000 or more) to obtain a collection of bootstrap statistics.\n",
    "\n",
    "4. Calculate confidence interval: From the collection of bootstrap statistics, determine the lower and upper percentiles that correspond to the desired confidence level. For example, a 95% confidence interval would typically involve the 2.5th and 97.5th percentiles of the bootstrap distribution.\n",
    "\n",
    "5. Report the confidence interval: The lower and upper values obtained from step 5 represent the lower and upper bounds of the confidence interval, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a567db0",
   "metadata": {},
   "source": [
    "# Q8. Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb02d02",
   "metadata": {},
   "source": [
    "Bootstrap is a resampling method used to estimate the sampling distribution of a statistic or to assess the variability and uncertainty associated with a parameter estimate. It allows us to make inferences about a population based on a single sample. The general steps involved in bootstrap are as follows:\n",
    "\n",
    "1. Collect the original sample: Start with a dataset containing the original observations or data points.\n",
    "\n",
    "2. Resampling: Randomly select observations from the original sample with replacement to create a bootstrap sample. The size of the bootstrap sample is typically the same as the size of the original sample, but some observations may appear multiple times, while others may be left out. The use of replacement allows each observation to have an equal chance of being selected in each iteration, and it mimics the sampling process.\n",
    "\n",
    "3. Calculate the statistic: Compute the desired statistic (mean, median, standard deviation, etc.) of interest using the bootstrap sample. This statistic can be any measure that provides insights into the population parameter or distribution.\n",
    "\n",
    "4. Repeat steps 2 and 3: Repeat the resampling process multiple times (often a large number, such as 1000 or more) to obtain a collection of bootstrap statistics. Each iteration generates a new bootstrap sample and computes the statistic of interest.\n",
    "\n",
    "5. Estimate the sampling distribution: From the collection of bootstrap statistics, analyze the distribution of the statistic. This can be done by examining summary statistics (mean, median, standard deviation) or constructing histograms or confidence intervals.\n",
    "\n",
    "6. Make inferences: Use the sampling distribution obtained from the bootstrap to make inferences about the population parameter. For example, you can calculate confidence intervals or perform hypothesis tests based on the distribution of bootstrap statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec3672",
   "metadata": {},
   "source": [
    "# Q9.Ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485d6085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap mean: 15.00\n",
      "Bootstrap standard deviation: 0.00\n",
      "95% Confidence interval: (15.00, 15.00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Original sample data\n",
    "sample_heights = np.array([15] * 50)  # assuming all heights are 15 meters\n",
    "\n",
    "# Bootstrap resampling\n",
    "n_iterations = 1000\n",
    "bootstrap_means = []\n",
    "for _ in range(n_iterations):\n",
    "    bootstrap_sample = np.random.choice(sample_heights, size=len(sample_heights), replace=True)\n",
    "    bootstrap_mean = np.mean(bootstrap_sample)\n",
    "    bootstrap_means.append(bootstrap_mean)\n",
    "\n",
    "# Calculate the mean and standard deviation of bootstrap means\n",
    "mean_bootstrap_means = np.mean(bootstrap_means)\n",
    "std_bootstrap_means = np.std(bootstrap_means)\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "lower_bound = np.percentile(bootstrap_means, 2.5)\n",
    "upper_bound = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "# Print the results\n",
    "print(\"Bootstrap mean: {:.2f}\".format(mean_bootstrap_means))\n",
    "print(\"Bootstrap standard deviation: {:.2f}\".format(std_bootstrap_means))\n",
    "print(\"95% Confidence interval: ({:.2f}, {:.2f})\".format(lower_bound, upper_bound))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6c246a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
