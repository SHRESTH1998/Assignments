{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "10f7d8da-c021-43f0-99ec-c077f4abc945",
      "metadata": {
        "id": "10f7d8da-c021-43f0-99ec-c077f4abc945"
      },
      "source": [
        "Q1. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5a42e96-66bd-4765-93d9-0e5ff0e17735",
      "metadata": {
        "id": "a5a42e96-66bd-4765-93d9-0e5ff0e17735"
      },
      "source": [
        "Lasso regression is a regularization technique. It is used over regression methods for a more accurate prediction. This model uses shrinkage. Shrinkage is where data values are shrunk towards a central point as the mean.\n",
        "\n",
        "Lasso Regression is different from ridge regression as it uses absolute coefficient values for normalization. As loss function only considers absolute coefficients (weights), the optimization algorithm will penalize high coefficients. This is known as the L1 norm."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c67aea15-74b2-45c1-a064-155faf9877fa",
      "metadata": {
        "id": "c67aea15-74b2-45c1-a064-155faf9877fa"
      },
      "source": [
        "Q2. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad21d2e-ce5c-4180-9950-a14aa4920253",
      "metadata": {
        "id": "3ad21d2e-ce5c-4180-9950-a14aa4920253"
      },
      "source": [
        "The main advantage of a LASSO regression model is that it has the ability to set the coefficients for features it does not consider interesting to zero. This means that the model does some automatic feature selection to decide which features should and should not be included on its own."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86613204-dd2d-4f4c-8702-88737d58390d",
      "metadata": {
        "id": "86613204-dd2d-4f4c-8702-88737d58390d"
      },
      "source": [
        "Q3. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "924f43ff-54f1-40ee-8291-b132d7f9f83a",
      "metadata": {
        "id": "924f43ff-54f1-40ee-8291-b132d7f9f83a"
      },
      "source": [
        "Ridge regression (L2 regularization) shrinks coefficients towards zero, whereas lasso regression (L1 regularization) can force some coefficients to be exactly 0, making it suitable for feature selection."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "358c0425-59ba-4751-8e61-32e4f8cd5086",
      "metadata": {
        "id": "358c0425-59ba-4751-8e61-32e4f8cd5086"
      },
      "source": [
        "Q4. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efefa127-0352-41c6-bd49-b64683594fa9",
      "metadata": {
        "id": "efefa127-0352-41c6-bd49-b64683594fa9"
      },
      "source": [
        "A tuning parameter (Î»), sometimes called a penalty parameter, controls the strength of the penalty term in ridge regression and lasso regression. It is basically the amount of shrinkage, where data values are shrunk towards a central point, like the mean."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8e613fb-5cad-44ae-8767-685c4cf5dbba",
      "metadata": {
        "id": "f8e613fb-5cad-44ae-8767-685c4cf5dbba"
      },
      "source": [
        "Q5. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa30d591-015d-4498-b4d3-86954ee3eb3f",
      "metadata": {
        "id": "aa30d591-015d-4498-b4d3-86954ee3eb3f"
      },
      "source": [
        "The ordinary lasso penalty has been extensively used in the framework of linear regression models; however, sufficient results have not been obtained for nonlinear regression models with Gaussian basis functions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d56352f-e9b8-418d-8302-e37445bb579f",
      "metadata": {
        "id": "1d56352f-e9b8-418d-8302-e37445bb579f"
      },
      "source": [
        "Q6. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54e52a95-1c23-4f3c-a90e-010a4f59f8de",
      "metadata": {
        "id": "54e52a95-1c23-4f3c-a90e-010a4f59f8de"
      },
      "source": [
        "Similar to the lasso regression, ridge regression puts a similar constraint on the coefficients by introducing a penalty factor. However, while lasso regression takes the magnitude of the coefficients, ridge regression takes the square. Ridge regression is also referred to as L2 Regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6217710-8098-4fc1-a909-a163a3f91799",
      "metadata": {
        "id": "b6217710-8098-4fc1-a909-a163a3f91799"
      },
      "source": [
        "Q7. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0268428c-e823-49f8-93c6-7439af374351",
      "metadata": {
        "id": "0268428c-e823-49f8-93c6-7439af374351"
      },
      "source": [
        "Lasso Regression\n",
        "Another Tolerant Method for dealing with multicollinearity known as Least Absolute Shrinkage and Selection Operator (LASSO) regression, solves the same constrained optimization problem as ridge regression, but uses the L1 norm rather than the L2 norm as a measure of complexity."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36d4bb44-2297-494a-9d00-f3628bc9a0a4",
      "metadata": {
        "id": "36d4bb44-2297-494a-9d00-f3628bc9a0a4"
      },
      "source": [
        "Q8. Ans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b02642ec-a3dc-4934-b2e4-edeb0ac54687",
      "metadata": {
        "id": "b02642ec-a3dc-4934-b2e4-edeb0ac54687"
      },
      "source": [
        "When choosing a lambda value, the goal is to strike the right balance between simplicity and training-data fit: If your lambda value is too high, your model will be simple, but you run the risk of underfitting your data. Your model won't learn enough about the training data to make useful predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "179e283b-87f4-4885-a13d-e57f25493c0a",
      "metadata": {
        "id": "179e283b-87f4-4885-a13d-e57f25493c0a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}